<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
    <title>Static Oneplus</title>
    <description>不可控制论</description>
    <link>http://yjliu.net</link>
    <atom:link href="http://yjliu.net/feed" rel="self" type="application/rss+xml" />
    
    <item>
        <title>写点什么吧</title>
        <description><![CDATA[ <p>在年轻而且精力旺盛的那几年，我们都多多少对写博客有那么点兴趣。
我刚开始维护独立博客的那段时间，基本是以每周一篇的速度更新。
相比现在，变成了半年一篇，产量大幅度降低质量却没有明显提升。
由此我知道我在退步。</p>

<p>去年末，larrylv学长朝我说linode应该不会续租了。
但后来又拖了半年，所以oneplus.info还在正常运转。
感谢学长的照顾。</p>

<p>曾经想过要接着学长的主机租下去。
但是一想到维护的成本，或许一两年还可以接受，时间长了可能就难了。</p>

<p>现在我已经没有精力去维护复杂的博客系统。
没心思考虑用什么样的主题，什么样的插件。
不想在CSS上花一分钟时间。</p>

<p>所以Static Oneplus变成了现在这样。</p>

<p>我在Jekyll非常早期的版本的基础上开发了一个可以把日志和技术笔记合并到一个站点的静态页生成工具。
然后用他来生成网站。
分类、标签、分页这些功能都没有开发。
旧的主题也完全弃用。
所谓新的主题就是在整个网站上加了一个bootstrap.css的container。</p>

<p>我也不想考虑博客的访问速度，稳定性。
这些都交给github吧。</p>

<p>曾经对于写博客这件事充满热情与幻想。
也终于3年后逐渐慢下了脚步。</p>

<blockquote><p>有些事我们无法改变啊
在一个变幻的年代</p></blockquote>

<p>所以最后我们输给的都是时间。</p>
 ]]></description>
        <pubDate>Wed, 05 Feb 2014 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2014/02/05/write-something.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2014/02/05/write-something.html</guid>
    </item>
    
    <item>
        <title>doubanclaim46bd04b96fa18c3a</title>
        <description><![CDATA[ <p>rt</p>
 ]]></description>
        <pubDate>Wed, 05 Feb 2014 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2014/02/05/douban-claim.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2014/02/05/douban-claim.html</guid>
    </item>
    
    <item>
        <title>研一这一年吧</title>
        <description><![CDATA[ <p>给这一年列一个时间表吧，这篇文章想写很久了，虽然有预感写出来又是满满的负能量。</p>


<p><a id="more"></a><a id="more-826"></a></p>

<h3>2012年</h3>


<h4>8月-9月</h4>


<p>写了一篇叫《基于序列标注的中文分词、词性标注模型比较分析》，投了一个学生会议。大概是想论证用分类方法做分词、词性标注这些序列性问题可以取得与序列标注模型类似的性能。还想强调分类速度比较快。不过实验并没有获得符合预期的结果。所以这篇论文的论点比较奇怪，不管是写还是修改都很痛苦。在后来被转投中文信息学报，我又不得不痛苦地改了一遍。</p>


<h4>9月-10月</h4>


<p>参加了微博分词的评测。最后提交的系统是一个混了一大坨预处理的特征、半监督特征的CRF模型。除了把别人论证过的东西实现了一通后，几乎没有引入什么有新意的东西。由于官方没公布评测排名，并不知道自己的系统排名如何，但开会时统计了一下，大概是第二的位置。大概半年后，我review这个系统时发现当时使用crfsuite工具训练模型时没把负特征开关打开，所以最终结果应该是高于提交的系统的结果的。但主办方也没公布数据，也没法去做实验。</p>


<h4>10月-11月</h4>


<p>拿出不多的时间学习了机器学习，包括实现了一些简单的机器学习算法。重组织了博客。调研了一部分domain adaptation的论文，改之前的水文。还有一些杂七杂八的上课实验什么的。</p>


<h4>11月-12月</h4>


<p>写微博分词的评测报告，同时也看一段gibbs抽样。准备去上海开会的报告以及去开会，接着改论文投中文信息学报。</p>


<h4>12月-1月</h4>


<p>前半段考试，做了一坨课程实验，后半段去天津开了微博分词的会，其间都是准备poster一些杂事。这月后半段开始接了网管的工作。这其间还草草做了一个字聚类帮助分词的实验。后来这个非常烂的idea投了ccl2013。</p>


<h3>2013年</h3>


<h4>1月-2月</h4>


<p>前半段修硬盘来着。刚接手网管，实验室的磁盘阵列就挂了。大概原因就是raid5坏了两块后没人知道，第三块坏后就彻底挂了。大冬天抱着硬盘跑数据恢复，反正是非常苦逼。后来十天草草准备了一下托福，一战成了挂逼。</p>


<h4>2月-3月</h4>


<p>打算考G，利用过年时间背了一个多月单词，约了5月的G和6月的T。</p>


<h4>3月-5月</h4>


<p>开始调研用deep learning做分词，基本把rnnlm看了一遍。最初的思路是用语言模型做分词，结果做出来就让人没什么信心，后来又把思路换成用embedding做semi-supervised，也没什么信心。当时觉得主要问题在embedding结果对于分词模型不是线性作用的。也想过用c&w直接做一个分词的神经网络，不过后来看ccl好像有中科院的同学用实现了这个思路，不过效果似乎也让人没什么信心。不知道dl是不是不适合参加自然语言处理的battle against state-of-the-art。</p>


<p>断断续续地准备英语。</p>


<p>这两个月中做的另外一件事是机房上新设备。配上机器，电路改造，修空调，反正很少能安心下来看看书或者读读论文，跑实验也总出错。</p>


<h4>5月-6月</h4>


<p>面对一坨考试，终于撑不住了。取消的5月的G。不过考试还是成功考出两科60分。</p>


<h4>6月-8月</h4>


<p>在万念俱灰的情绪下，用一个星期整理了之前cluster帮助分词的工作。想论证怎样做字的表示才能帮助分词任务，结论是对单个字做不靠谱，对字聚类时要考虑字的上下文信息。这个水文投出去后重构了正华师兄的依存句法分析器dparser。当时估计工作量大概是一个月，1万行代码以下。但是实际做起来发现可以顺势将ltp里面的其他模块也重构一下。结果就是重写了本科毕设的序列标注统一框架，整个项目下来有1.7万行代码。还有9K字的文档，再加上写了python和ruby两个版本的client和一部分web页面。总之这两个月彻底做了一只代码狗。</p>


<p>6月末托福二战，再次准备十天，再次挂逼，考了个什么都不能做的93。基本是死了出国这条心了。</p>


<p>再一件事是实验室网站被挂马，被网络中心关站了。没办法用静态页生成器重构了主页，迁移+升级了服务器，跑了几趟网络中心。现在还有一些服务没恢复，拙计。</p>


<p>这一年，基本上是在一种忙碌而压抑的状态中度过。没怎么过过周末，也没时间去运动。体重又回到了110斤以下，可悲的是肚子好像有胖的趋势。前个周末，爸妈来哈尔滨，幸亏没买到车票。因为那天综合楼停电，结果来电后机房就烧到50度了。若是他们来，恐怕只能把他们撂旅馆里一天了。</p>


<p>有的时候，我也不知道想过什么应该怎样生活。也没时间去想一想，反正一直被无形的力量推动，不由自主。</p>


<p>他们大四的毕业那会儿，我有几次被三点唱歌的醉汉们吵醒。只好去公寓平台的椅子里乘凉，有时看天色由黑转灰，继而一片青蓝，觉得很陌生。</p>

 ]]></description>
        <pubDate>Mon, 05 Aug 2013 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2013/08/05/summary-on-first-year-as-graduate-student.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2013/08/05/summary-on-first-year-as-graduate-student.html</guid>
    </item>
    
    <item>
        <title>脱臼</title>
        <description><![CDATA[ <p>昨天睡觉前，躺在床上打了个哈欠，结果一不小心下巴脱臼了。</p>


<p><a id="more"></a><a id="more-819"></a></p>

<p>下巴脱臼已经不是一次两次了。第一次脱臼好像是由于吃苹果张太大口，后来则以打哈欠打脱臼了居多。我把这种病症归咎于基因，因为印象中我妈好像也脱臼过。可能是骨骼的构造不合适，也可能是韧带的力度不够，不过这些一定是由基因决定的。由于接受了这种设定，我也就比较释然，重来没埋怨过苹果或者是哈欠。</p>


<p>出于多次脱臼的经验，我已经学会了一些基本的救治手段。一般是将下巴向左稍用力顶一下，感觉头骨错动，也可能会听到咯噔一声。如果运气好，脱臼就归位了。运气不好就多试几次，总有那么一次成功的。</p>


<p>我对自己的身体还有自己的技术都是有一定信心的，所以躺在床上左手扶头，右手扶下巴，向左用了一下力。可惜没出现咯噔一声。我知道我失败了，休息了几秒，换了个姿势，又向左使了一下力，当然还是失败。“或许是躺着不方便”，这么想后，我便坐了起来，哈尔滨夏夜的凉风慢悠悠地从窗子吹了进来。我额头上有汗，所以敏锐地捕捉到了这阵不期而遇的夏天的风。</p>


<p>坐起来后，我又重复了几次相同的自救策略，都以失败告终。好在我并没有着急，大学这几年唯一教会我的就是在着急之前先平静一下。平静的片刻之后，一大坨信息就冲入我的脑中：“首都机场好像发生爆炸案了”；“是不是城管最近又打死人了”；“托福口语如何提高成绩，真着急”；“昨天复华那边打架来着”；“不知道当年温岚有没有和周杰伦好过”；“女神建议我换个孙燕姿的桌面，要不要考虑一下”；“最近好像写了很多代码，都快成狗了”；“哎，活着真没意思”；“不过我还是不要告诉别人，免得看起来像个怨妇”。</p>


<p>在一阵激烈的对于宇宙终极问题的思考之后，我意识到“这次脱臼好像是自己弄不好了。”</p>


<p>而这时，寝室里另外一个哥们打起了呼噜，配着青黑天空中闪烁的繁星，显得非常有节奏。</p>


<p>大概又经历了一次尝试的失败，我放弃了治疗。小心翼翼穿上衣服。我要去医院，这件事不怎么严重，不必惊动其他人，我自己就够了。</p>


<p>“我是多么独立的一个人”， 我这么想着瞄了一眼寝室的镜子，以确保自己脱臼的嘴脸在旁人看起来不那么可憎。</p>


<p>然后，一切妥当后，我拖着着这副夸张的对世界惊呆了的表情走入了孤独的夜色之中。</p>


<p><a href="http://blog.oneplus.info/wp-content/uploads/2013/07/暴走漫画-www.iPc_.me33.png"><img src="http://blog.oneplus.info/wp-content/uploads/2013/07/暴走漫画-www.iPc_.me33.png" alt="" title="superize" width="118" height="145" class="aligncenter size-full wp-image-820" /></a></p>
 ]]></description>
        <pubDate>Sun, 21 Jul 2013 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2013/07/21/luxation.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2013/07/21/luxation.html</guid>
    </item>
    
    <item>
        <title>实现一个更快一点的hashmap</title>
        <description><![CDATA[ <p>这段时间在写parser，难免又碰到了特征映射的问题。去年毕设做分词、词性标注时，这部分是用__gnu_cxx::hash_map<string,int>来实现的。下表显示了几种数据集条件下的特征字典规模。
<table width="100%" border="1">
<tr><td>数据集</td><td>Ctb5</td><td>Ctb7</td><td>People’s Daily</td></tr>
<tr><td>数据规模</td><td>1.8W sent.</td><td>4.7W sent.</td><td>18.4W sent.</td></tr>
<tr><td>分词特征规模</td><td>203.1W</td><td>334.8W</td><td>774.9W</td></tr>
<tr><td>词性标注特征规模</td><td>158.7W</td><td>274.2W</td><td>751.3W</td></tr>
</table>
</p>


<p><a id="more"></a><a id="more-786"></a></p>

<p>对于这个级别的数据量，在特征检索过程中，特征字典的性能已经对于整个分析器的性能产生了影响。不过，分词词性标注都是序列模型，对于序列中的每个元素，只要相应进行一次抽取就可以，特征字典的性能提高一点或者降低一点，对于整体速度的影响并不是非常明显。</p>


<p>不过在parser中，特征检索的情况就有所不同了。主要表现就是作为一种结构学习，parser在学习模型参数以及预测过程中，需要对序列中的每两个元素抽取特征。假如我们有30种特征模板，30词的句子，放到词性标注任务中，需要进行30*30=900次特征检索，而放到依存句法分析中，就需要进行30*30*30=27000次特征检索。所以如果特征字典能再快点，当然是好事情。</p>


<p><p>另外一件让我比较不爽的事情是，c++的hash_map没法很好地支持持久化。我想把hash_map当成整段内存dump到磁盘上，没可能。只能一个key-value，一个key-value地处理。所以呢，最理想的是有这样一种hash map
<ul><li>是一种动态的词典</li>
<li>以string或者const char * 作为key</li>
<li>性能与__gnu_cxx::hash_map相近，或者更胜一筹</li>
<li>能够很方便地进行持久化</li>
<li>不需要考虑删除操作</li>
</ul>
<h3>数据持久化</h3>
<p>进一步分析，要对数据进行持久化，最好的办法就是把所有的数据都放到一段内存上，dump的时候，直接把这段内存写到磁盘上；load时，直接从磁盘中读一段内存。池子一下子变成了一个超级好的选择。stl中的string基本没法持久化，不用想了。const char <em>倒是不错。我们可以把所有的key都固化到一段char </em>的buffer中。</p>
<p>对于value的固化，其实有这样一种考虑：如果value的类型是可以固化的，比如说int、double，那么也可以用池子来存这些value，但是如果是一些自建类型，比如说类啊什么的，本来就没有很直接的持久化的方法，小店也就只能伺候不周了。</p>
<p>池子固然是好想法，但我们考虑数据结构的动态性还要大于其性能考虑。想让池子变得动态基本就要用到stl中的allocator的技术了。维护一个池子长度上限以及当前长度，如果新加入的元素的规模大于池子上限，就将上限翻倍，重新给池子分配一段空间，把旧空间拷贝过去。</p>
<p>这样的话，数据固化的问题基本可以沿着这个思路解决。简单的代码可以写成这样
<div>
  <pre class="prettyprint linenums 1"><code class='cpp'>if (pool_cap &lt;= (new_size=(pool_size+element_size))) {
    pool_cap=((new_size)&lt;&lt;1);
    Element_type * new_pool = new Element_type[pool_cap];
    std::copy(pool, pool + pool_size, new_pool);
    delete <a href="pool"></a>;
    pool = new_pool;
}</code></pre>
</div></p>

<p><h3>性能优化</h3>
<p>虽然hashmap中hash function是很大程度上影响性能的因素，但是这也是我们不能控制的事情。我们能够提供的大概只有给一个合理的hashtable大小，以使得碰撞不是非常剧烈。什么样的hashtable大小比较合适，开大了浪费，开小了碰撞又多，看来又要上动态的hashtable了。不过即便是动态的hashtable，也面临resize时机的问题，爆栈上有这样一个问题“<a href="http://stackoverflow.com/questions/1603712/when-should-i-do-rehashing-of-entire-hash-table/1604428#1604428">When should I do rehashing of entire hash table?</a>”，第一条答案给了一个经验性的回答，翻译整理一下：
<blockquote>首先需要明确一个量load factor的概念，这个值表示hashtable的桶的个数M和桶中元素的个数N的比值，load factor=N/M。然后看一看你所使用的hashtable的类型有关（关于load factor和hashtable类型都可以去看侯捷老师的stl源码分析的5.7.1节）。
<ul><li>线性探测（linear probing）：load factor在60%左右时就该resize了</li>
<li>二次探测（quadratic probing）：load factor在80%-85%时就该resize了</li>
<li>开链（separate chaining）：load factor大于150%时就该resize了</li>
</ul>
</blockquote>
</p>
<p>然后，我们还会面临一个问题，就是resize到多大呢？二倍当然是一个选择，但不一定是好选择，比如说二次探测的hashtable需要hashtable大小为质数，二倍了就不是质数了。比较好的选择是二倍以上的质数，这个<a href="http://planetmath.org/goodhashtableprimes">网址</a>给出了一个hashtable size的质数表。后来我发现stl中也有一样的质数表。</p>
<p>具体实现resize的时机是在hashmap每次insert一个元素之后，看一看是不是符合resize的机制。如果符合，申请一段新的hashtable，然后枚举旧的hashtable中的每个元素，把他们插入到新的hashtable中。</p>
<p>好的，到这里我们基本对于hashtable的实现心里也有数了。不过做出来的可能也只是hash_map的一个翻版，如何在性能上进一步提升呢？之前有一次讨论中，陆子龙师兄说在构造hashmap时可以将高频的key有限插入hashtable，这样从概率的角度讲，高频的key就有更多更大可能性一次就被检索到。这或许是一个优化的好思路，而且貌似gnu.trove已经实现了这种机制。</p>
<p>为了实现这一机制，用开链的方式显得要比其他几种容易。比方说保证高频key靠前，就只要保证在插入元素的时候维护链的有序性。因为每个链中都不会有很多元素，所以直接用类似于交换排序的思想就好了。维护有序性的时机主要是在某个key被重复插入后，这个key的频率增加，只要看一看这个key在链表中的前一个key是不是已经小于这个key了，如果是，就往前交换就好了。因为每个链都比较小，而且在频率增加前这个链是有序的，所以可以在极小时间复杂度内求出算某个key的正确位置时。</p>
<p>到这里基本上整个数据结构的设计就出来了。Hash node设计成
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>struct hash_node_t {
public:
        unsigned int <strong>key_off; // 存key在key_pool中的偏移量
        unsigned int </strong>val_off; // 存value在value_pool中的偏移量
        unsigned int <strong>freq; // 存频次
        unsigned int </strong>hash_val; // 存hashvalue，用于加速
        int __next_off; // 存后继节点在node_pool中的偏移量</p>

<p>};</code></pre>
</div></p>

<p></p>
<p>因为池子的地址会动态变化，不能直接在hash node中保存指针，存偏移量就没有问题了。</p>
<p>一共有三个pool，一个存key，一个存value，一个存hash node，另外一个指针数组（或者偏移量数组）存hashtable的头结点，就设计成如下图那样了。</p>
<p><a href="http://blog.oneplus.info/wp-content/uploads/2013/06/structure.jpg"><img src="http://blog.oneplus.info/wp-content/uploads/2013/06/structure.jpg" alt="Hash Table的数据结构" title="structure" width="500" class="aligncenter size-full wp-image-805" /></a></p>
<p>我实现的代码放在<a href="https://github.com/Oneplus/libutilities/blob/master/src/smartmap/smartmap.hpp">这里</a></p>
<h3>测试</h3>
<p>为了证明这个hashmap的性能，我进行了一个简单的benchmark。数据完全是模拟现实情境中首先构造特征字典，然后进行特征检索。benchmark的方法参考了<a href="incise.org/hash-table-benchmarks.html">这篇博客</a>中的方法。评价的大体过程是首先用一个有重复元素的key字典构建字典，然后用一个比较大规模的key集合去检索他的value。评价中采用了三个数据集，分别是ctb5，ctb6的分词特征集，和cdt的一阶句法特征集。key集是构造特征空间时用到的key，retrieve集是全特征集。各个数据的统计如下表所示
<table width="100%" border="1">
<tr><td>data set</td><td># of keys</td><td># of unique keys</td><td># retrieve entries</td></tr>
<tr><td>CTB5</td><td>12.89M</td><td>2.2M</td><td>77.3M</td></tr>
<tr><td>CTB6</td><td>16.91M</td><td>2.7M</td><td>101.5M</td></tr>
<tr><td>CDT</td><td>55.6M</td><td>5.2M</td><td>198.9M</td></tr>
</table>
</p>
<p>参与对比的hashmap有__gnu_cxx::hash_map，google_sparse_hash，google_dense_hash，几种hashtable都做了类似的封装。benchmark用到的代码地址在<a href="https://github.com/Oneplus/libutilities/tree/master/benchmark/smartmap">这里</a>。运行的时候用
<div>
  <pre class="prettyprint linenums 1"><code class=''>nice -n-20 ionice -c1 -n0 python bench.py</code></pre>
</div></p>

<p>保证了进程的优先级。
</p>
<p>实验在xeon5650 2.67GHz的服务器上进行，gcc版本是比较老的4.1.2。</p>
<p>在实验数据集上，时间效率和内存效率分别如下表显示。</p>
<p><a href="http://blog.oneplus.info/wp-content/uploads/2013/06/speed.png"><img src="http://blog.oneplus.info/wp-content/uploads/2013/06/speed.png" alt="" title="speed benchmark" width="500"  class="aligncenter size-full wp-image-810" /></a></p>
<p><a href="http://blog.oneplus.info/wp-content/uploads/2013/06/memory.png"><img src="http://blog.oneplus.info/wp-content/uploads/2013/06/memory.png" alt="" title="memory benchmark" width="500" class="aligncenter size-full wp-image-811" /></a></p>
<p>总体上来讲是达到了我的期望。下一步打算把这个模块并入LTP中，期望还能再进一步优化！</p>
<h3>参考资料</h3>
<ul>
<li><a href="http://book.douban.com/subject/1110934/">STL源码分析</a></li>
<li><a href="http://stackoverflow.com/questions/1603712/when-should-i-do-rehashing-of-entire-hash-table/1604428#1604428">When should I do rehashing of entire hash table?</a></li>
<li><a href="http://incise.org/hash-table-benchmarks.html">Hash Table Benchmarks </a></li>
</ul>
<p>话说好久没写博客了。</p></p>
 ]]></description>
        <pubDate>Tue, 18 Jun 2013 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2013/06/18/implementation-of-a-faster-hashmap.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2013/06/18/implementation-of-a-faster-hashmap.html</guid>
    </item>
    
    <item>
        <title>小记博客重组织</title>
        <description><![CDATA[ <p><a href="http://oneplus.info">oneplus.info</a>这个域名和它使用的主机空间是我在2011年初买下的。到现在，就快有两年的时间了。两年之间，这个里产生了38篇博文，接受了2.4万次PV，其中《<a href="http://blog.oneplus.info/archives/535">哈工大男女比例调研报告</a>》和《<a href="http://blog.oneplus.info/archives/455">关于一个点歌社交网络的构想</a>》两篇得到了豆瓣九点首页的推荐。总的来讲，我对博客中提供的内容还是比较用心。</p>


<p><a id="more"></a><a id="more-762"></a></p>

<p>虽然这个博客的一直以来的表现也没什么差错，但是我却在很早以前就产生了重新组织网站结构的想法。建站之初，没什么经验（现在我也没什么经验），直接把wordpress安装在web根目录public_html下，oneplus.info的域名也直接定位到博客上。到了现在，觉得有必要在这里加一个主页，把原来的博客移到blog.oneplus.info的域名下。出于这个考虑，这周在业余时间里完成了这两项工作。</p>


<h4>WordPress迁移</h4>


<p>在迁移之前，我的public_html是这样的：
<a href="http://blog.oneplus.info/wp-content/uploads/2012/10/before.jpg"><img src="http://blog.oneplus.info/wp-content/uploads/2012/10/before.jpg" alt="" title="before" width="399" height="282" class="aligncenter size-full wp-image-764" /></a>
我希望它变成这样，
<a href="http://blog.oneplus.info/wp-content/uploads/2012/10/after.jpg"><img src="http://blog.oneplus.info/wp-content/uploads/2012/10/after.jpg" alt="" title="after" width="398" height="152" class="aligncenter size-full wp-image-765" /></a>
并且可以通过blog.oneplus.info来访问。
</p>


<p>要实现上面的效果，首先要做的工作是把blog.oneplus.info解析到主机的IP上。这个只需要在DNS服务商处给主域添加一个A记录，使得HOST_NAME为blog.oneplus.info的http请求发送给我的主机。我的DNS服务商是Godaddy，在Domain Manager面板上添加记录如下。
<a href="http://blog.oneplus.info/wp-content/uploads/2012/10/godaddy.jpg"><img src="http://blog.oneplus.info/wp-content/uploads/2012/10/godaddy.jpg" alt="" title="godaddy" width="550" class="aligncenter size-full wp-image-766" /></a>
添加后大概一个小时就生效了。</p>


<p>在DNS服务的工作做完后，要做的是使得主机能够处理这个请求。通过Google发现，这个问题大致可以通过三种途径解决，它们分别是：
<ul>
<li>配置apache服务器，添加Virtual Host</li>
<li>通过mod_rewrite模块把blog相关的请求重定向到blog.oneplus.info/blog/下</li>
<li>在cpanel中添加子域</li>
</ul>
这里面，对于用cpanel管理的主机，由于用户不能接触httpd，第一种方法不能实现。第二种方法有点麻烦，具体做法可以google“.htaccess”、“重定向”、“二级域名”这几个关键字。第三种方法最简单，只要在cpanel的子域一项中添加一个名为blog.oneplus.info的子域就好了，非常傻瓜。
</p>


<p>在主机可以处理blog.oneplus.info的请求之后，下一步就是wordpress的搬家了。由于，我使用的wordpress版本是3.3.1，而且是站内移动，搬家这件事就变得非常简单。具体做法是在“设置-&gt;常规”中将“WordPress地址”和“站点地址”都写成blog.oneplus.info。保存之后，站点会暂时坏掉。不过把wordpress相关的文件移动到blog文件夹下，修改就生效了。</p>


<p>进行这些操作后，blog.oneplus.info便可以正常访问了。但是，还有一个问题是，博客中有一些图片的链接还指向blog.oneplus.info/wp-content/，科学的做法是把数据库的导出，然后把所有blog.oneplus.info改成blog.oneplus.info再导入。</p>


<p>这些都做完了，博客的迁移工作基本就完成了。整个过程都没什么难度，但是我忽略了最早的一步，白白浪费了一个晚上的时间。</p>


<h4>Feed重定向</h4>


<p>博客迁移之后，我的博客从下面几个方面会受到影响：
<ul>
<li>博客的订阅</li>
<li>搜索引擎排名</li>
<li>wumii的喜欢按钮</li>
</ul>
对于写博客的人，第二项虽然很重要，但是能做的其实不太多（而且我挺反感SEO的，虽然我是学信息检索的）。所以，服务好自己的订阅用户才是要紧事。
</p>


<p>现在的情景是由于feed的输出地址发生了改变，原来通过blog.oneplus.info/feed进行的订阅失效了。打开Google Reader，查看自己博客的订阅，发现Statistic中显示Parsing Error。好在主域还在我的手里，只要把blog.oneplus.info/feed的请求重定向到blog.oneplus.info/feed就行了。</p>


<p>这里要用到前面说过的比较麻烦的mod_rewrite。做法是在web根目录下的.htaccess中添加重写条件和重写规则。现在我对feed的重写规则是这样的
<div>
  <pre class="prettyprint linenums 1"><code class=''>RewriteCond %{HTTP_HOST} ^blog.oneplus.info$
RewriteCond %{REQUEST_URI} ^/feed$ [NC]
RewriteRule .* http://blog.oneplus.info/feed [NC,L,R=301]</code></pre>
</div>

它的含义是把所有主机名为blog.oneplus.info，URI为/feed的请求都重定向到blog.oneplus.info/feed下。
</p>


<p>添加完重写规则后可以通过访问blog.oneplus.info/feed来测试一下重写规则是否生效。还有一些其他网站提供mod_rewrite的测试，比如说<a href="http://martinmelin.se/rewrite-rule-tester/">这里</a>，重定向失败的话可以把.htaccess投到这个网站中，找些样例测试一下。</p>


<p>至于第三项，我倒确实把男女比那篇的一百多个“喜欢”给丢了，不过I don't care。</p>


<h4>主页</h4>


<p>完成博客迁移后，我发觉应该给blog.oneplus.info写一个主页。最后决定在里面写一个个人简介（留着吹牛用）。这次，我想尝试一下css框架（平时在实验室里也没机会），于是把bootstrap、blueprint、foundation几个框架都试了试。最后还是决定用bootstrap，原因是我在网上找到了它对ie6做的patch。至于为什么要兼容ie6，这篇豆瓣<a href="http://www.douban.com/note/241422302/">日记</a>记录了原因。</p>


<p>后来我觉得应该在主页中加一个最近发布的博客。直接查库当然是个好选择，但是我还想在ir.hit.edu.cn/~yjliu/上面做个镜像。所以在主机上写了一个小php - query来查库。这样，blog.oneplus.info和ir.hit.edu.cn/~yjliu/都可以通过查这个网页获得最近的文章。不过，我的主机在国外，国内访问速度慢，而且这个网页的更新频率实在不高。做cache是必须的。</p>


<p>起初，我想了好久如何在query.php上做cache，后来才发现，最应该做cache的是主页这一端。所以在主页中添加了下面的代码：
<div>
  <pre class="prettyprint linenums 1"><code class='PHP'>$cache = new Cache(3600, &amp;quot;some_path&amp;quot;);

$key = &amp;quot;last_post&amp;quot;;
$values = $cache-&amp;gt;get( $key );

if ($values == false) {
    $page = '';
    $handler = fopen('some_url', 'r');

    while(!feof($handler)){
        $page .= fread( $handler, 1048576 );
    }
    fclose( $handler );
    
    $values = $page;
    $cache-&amp;gt;put( $key, $values );
    echo $values;
} else {
    echo $values;
}</code></pre>
</div>

对于主页的请求，先去看看cache过没过期，没过期就直接返回cache的结果，这样可以减少不少网络传输。其中，cache类我是参考<a href="http://www.mangguo.org/the-simple-php-cache-class/">这篇</a>的。
</p>


<h4>总结</h4>


<p>至此，博客的重组织工作告于段落。现在可以通过<a href="http://www.oneplus.info">www.oneplus.info</a>访问我的主页，也可以通过<a href="http://blog.oneplus.info">blog.oneplus.info</a>访问博客。虽然还有一些想做的工作，不过我还有别的事情，不能在这上面花太多时间，就这样吧。</p>


<p>PS: 这篇的另一目的是测试一下Feed输出是否正常。</p>

 ]]></description>
        <pubDate>Sat, 13 Oct 2012 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2012/10/13/restruct-my-blog.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2012/10/13/restruct-my-blog.html</guid>
    </item>
    
    <item>
        <title>实现一个线程安全的logging库</title>
        <description><![CDATA[ <h4>Introduction</h4>


<p>
Log是用来记录程序事件的一系列打印信息，和调试时的printf大法有点像。Log和我所接触的工作关系还是比较密切的。比方说，打印一下模型的加载时间、句子的解析速度、开发集上准确率什么的。由于接下来一段时间的工作需要写多线程，网上的logging库又不怎么习惯，所以计划造一个Log库的轮子。这篇文章中大概会讨论下面两方面内容：
<ul><li>用singleton模式实现logging库</li>
<li>Singleton模式的线程安全</li></ul>
</p>


<p><a id="more"></a><a id="more-726"></a></p>

<h4>Singleton</h4>


<p>单件(Singleton)是设计模式的一种。如果你的程序中有某个类在程序整个的生命周期中只能被实例化一次，那么这个类就可以用单件模式来实现。直白一点说，有时候单件扮演了和全局变量类似的角色。在实际应用场景中，我们的程序中只被实例化的例子有很多，比如说：存储配置项的类。但实际并不是所有符合单件模式情景的类都要用单件来实现，不过这个已经超出本文讨论范围了。</p>


<p>从OO的视角看打印log的对象(Logger)也具有只被实例化一次的特点。所以，用单件模式来实现Logger问题不大。</p>


<p>
首先把设计模式书上的代码抄一遍：
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>class Singleton {
   public:
       static Singleton* getInstance( );
   private:
       Singleton( );
       static Singleton* instance;
};</code></pre>
</div>

</p>


<p>然后，要做的就是往里面填一个打印log的函数，这个也是很容易实现的。实现后的效果如下。
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>class logger {
public:
    static logger * get_logger() {
        if (_instance == NULL) { _instance = new logger(); }
        return _instance;
    }

    void write_log(int i) {
        fprintf(stderr, &quot;%%levelname%% &quot;);
        fprintf(stderr, &quot;log: %d\n&quot;, i);
    }
private:
    static logger * _instance;
protected:
    logger() { }
};

logger * logger::_instance = NULL;

int main() {
    logger::get_logger()-&gt;write_log(10);
    return 0;
}</code></pre>
</div>
</p>


<p>当然也可以用变长参数和宏函数配合把这个做得有点酷，不过那些也不是本文要讨论的。</p>


<p>到这里，使用Singleton实现logger的任务已经完成得差不多了。接下来要做的是使上面的代码线程安全。</p>


<h4>线程安全</h4>


<p>相比解释线程安全(Threads Safety)的概念，我觉得说明线程不安全更加容易。就拿前面说到的logger做例子。如果我开若干个线程，每个线程调用logger::get_logger()->write_log(tid);搞不好就会出现如下图的情况，
<a href="http://blog.oneplus.info/wp-content/uploads/2012/10/thread_safety.png"><img src="http://blog.oneplus.info/wp-content/uploads/2012/10/thread_safety.png" alt="" title="thread_safety" width="266" height="52" class="aligncenter size-full wp-image-728" /></a>
这里就出现两个线程都向stderr打印，导致打印信息混乱了。如果write_log函数中做更复杂的操作，出现这种混乱的可能性会变得更大。造成这一现象的原因就是多个线程抢占同一文件句柄，是生产者消费者问题的一个具体情境。解决方法就是给write_log上互斥锁。把write_log函数改成下面的样子就好了。
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>void write_log(int i) {
    EnterCriticalSection();
    fprintf(stderr, &quot;%%levelname%% &quot;);
    fprintf(stderr, &quot;log: %d\n&quot;, i);
    LeaveCriticalSection();
}</code></pre>
</div>

</p>


<p>不过，给write_log上锁也并不能完全保证logger线程安全，另一个非常隐蔽资源抢占会发生在单件实例化的那个时间上。如果logger并没被初始化，并且又有多个线程同时要去初始化它，而在初始化时发生上下文切换，那么这个logger就会被实例化多次。</p>


<p><a href="http://www.codeproject.com/Articles/96942/Singleton-Design-Pattern-and-Thread-Safety">这里</a>提供了三种解决方法，第一种是直接在判断单件是否被实例化前加锁，代码如下：
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>static logger * get_logger() {
    EnterCriticalSection();
    if (_instance == NULL) { _instance = new logger(); }
    LeaveCriticalSection();
    return _instance;
}</code></pre>
</div>

由于加互斥锁是一件比较耗时的工作，每次get_logger时都调用会加锁，解锁，程序的速度会受到影响。总之，这种方法是比较不赞的。</p>


<p>第二种是在程序一开始就将它实例化（这种方法给人感觉也不怎么好）。弊端是如果这个单件在整个程序生命中都没有被调用，那么这次实例化就浪费了。当然浪费掉的还包括一些系统资源。</p>


<p>第三种方法在第一种方法上进行改进，把加锁放在if判断里面，或者说在加锁外放一层if判断，代码是这样的：
<div>
  <pre class="prettyprint linenums 1"><code class='CPP'>static logger * get_logger() {
    if (_instance == NULL) {
        EnterCriticalSection();
        if (_instance == NULL) {_instance = new logger(); }
        LeaveCriticalSection();
    }
    return _instance;
}</code></pre>
</div>

这种方法的好处是避免了每次get_logger都加锁，不过在某些情景上和第一种方法是一样的。</p>


<h4>printf</h4>


<p>在实验过程中，我发现如果write_log只调用一次printf，并不会出现前面谈线程安全时的输出混乱。查了一下发现，printf本身具有操作原子性。所以，如果write_log函数只由一个printf组成，那一处的锁也可以忽略。</p>


<p>最后形成的代码放在github的<a href="https://github.com/Oneplus/libutilities/tree/master/src/logging">这里</a>。</p>


<p>牢骚几句，感觉操作系统很多基础知识都还给sunner了，罪过。</p>




<h4>参考</h4>


<p><ul>
<li><a href="https://computing.llnl.gov/tutorials/pthreads/">POSIX Threads Programming</a></li>
<li><a href="http://www.codeproject.com/Articles/96942/Singleton-Design-Pattern-and-Thread-Safety">Singleton Design Pattern and Thread Safety</a></li>
<li><a href="http://stackoverflow.com/questions/467938/stdout-thread-safe-in-c-on-linux">stdout thread-safe in C on Linux?</a></li>
</ul></p>

 ]]></description>
        <pubDate>Sat, 06 Oct 2012 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2012/10/06/the-implementation-of-a-thread-safe-logging-library.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2012/10/06/the-implementation-of-a-thread-safe-logging-library.html</guid>
    </item>
    
    <item>
        <title>最大熵模型的简单实现</title>
        <description><![CDATA[ <p>谈到最大熵，真的是一个妇孺皆知老少咸宜的好模型。而且，网上确实已有大批量的论文、笔记、幻灯片介绍最大熵。所以，这篇的重点放在如何实现一个简单的最大熵分类器上。</p>


<p><a id="more"></a><a id="more-671"></a></p>

<h3>最大熵模型推导</h3>


<p>机器学习的任务是从数据中学习知识。我们做分类问题，看到的数据往往是每个实例对应一个类别。比如说词性标注中一个词对应一个标注。为了下面讨论的方便，将类别称为Outcome，将每个实例的上下文环境叫做Context。实例被称为Event，一个实例是Outcome与Context的二元组。</p>


<p>为了表示数据，我们从数据中抽取了一系列的特征。特征的全体可以看做是n个特征函数组成的一个集合。每个特征函数可以是从Context到0-1的二值函数。比方说这样的\[ f(x,y)=\{\begin{aligned} 1 & if\ x="is"\ and\ y=v \\ 0 & otherwise \end{aligned} \]一组特征函数就将Context从上下文空间映射到特征空间上了。</p>


<p>现在，我们观察到一组数据集，通过简单的统计可以知道任意一个Context x和Outcome y的组合的联合概率。有了联合概率，可以计算观察到的某一特征函数f的期望，也就是$ E_{ref}(f)= \sum_{x,y}{\tilde{p}(x,y)f(x,y)} $，称为观察期望/经验期望。</p>


<p>假设我们有一个模型给出p(y|x)的值，那么我们可以从这个模型的角度求出这个特征函数的期望，即$ E_q(f)=\sum_{x,y}{\tilde{p}(x)p(y|x)f(x,y)}$，称为模型期望。</p>


<p>我们希望我们的模型能够很好地反应这些数据中蕴含的现象。那么从模型角度看到的f的期望就应该等于从数据观察到的f的期望。也就是$ E_q(f)=E_{ref}(f) $</p>


<p>假设我们有n个特征函数，那么我们就有n组等式$ E_q(f_i)=E_{ref}(f_i), i \in {1,2,...,n}$。</p>


<p>假设我们有那么那么多的模型，也可以认为是概率分布。他们组成一个空间$ \mathcal{P} $，而满足上面一系列特征函数期望构成的等式的概率分布构成了$ \mathcal{P}$的一个子集\[ \mathcal{C}=\{p|p\in \mathcal{P} \quad and \ E_q(f_i)=E_{ref}{f_i},\ i \in (1,2,...,n)\} \]</p>


<p>现在要找一个合适的模型描述数据，也就是在$ \mathcal{P} $中搜索一个p。然后这时，熵突然出现了（- -b这里我也不知道怎么写，原谅我吧），从最大熵的角度来看，这个模型需要满足上面一系列特征函数期望构成的等式（换句话讲，是一些列一系列特征函数期望构成的约束），同时尽可能将可能性均匀地非配到不确定的上下文情况中。</p>


<p>对于一个模型p，它的熵的定义是这样$ H(p)=-\sum_{x,y}\tilde{p}(x)p(y|x)\log{p(y|x)}$。熵越大，可能性就越平均地被分配，因而我们的最终目标是最大化一个模型的熵。而由于有前面的约束等式，这个问题变成了一个有约束的最优化问题$ find \ p_*=arg{max_{p\in C}{H(p)}}$。</p>


<p>然后引入拉格朗日乘子$\lambda$，将等式约束的优化转换成无约束的最优化，得到\[ \Lambda(p,\lambda)=H(p)+\lambda\sum_i(E_q(f_i)-E_{ref}(f_i)) \]求导解p，得到一个与$\lambda$有关的函数\[p_{\lambda}(y|x)=\frac{1}{Z_{\lambda}(x)}\exp(\sum_i{\lambda_i f_i(x,y)})\]其中，$Z_\lambda(x)=\sum_y{\exp(\sum_i \lambda_i f_i(x,y))}$。将$p_{\lambda}$带入无约束优化的式子中，得到\[ \Psi(\lambda)=\Lambda(p,\lambda)=-\sum_x\tilde{p}\log{Z_\lambda(x)}+\sum_i{\lambda_i E_{ref}(f_i)} \]</p>


<p>推导到这里，我们基本得到了算法要做的工作，就是从数据中估计出一个特征函数的权向量$\lambda$。最大化\[ \Psi(\lambda) \]。</p>


<p>注意：
<ul>
<li>$\Psi(\lambda)$等于经验分布的最大似然估计，也就是$\Psi(\lambda)=L_p(\Lambda)$</li>
<li>上面的求导过程被忽略了</li>
<li>为什么最大化$\Psi(\lambda)$是正确的，这里涉及到原问题和对偶问题，还有KTT条件。我觉得应该是写不明白，所以直接跳过，不影响我们实现最大熵模型。</li></ul></p>


<h3>最大熵模型的实现</h3>


<p>要算$ \lambda $，解析解肯定是行不通的。对于最大熵模型对应的最优化问题，GIS，lbfgs，sgd等等最优化算法都能解。相比之下，GIS大概是最好实现的。算法的流程如下：</p>


<p>
<ol>
<li>初始化$ \lambda=0$</li>
<li>循环$ \lambda_i^{(t+1)}=\lambda_i^{(t)}+\frac{1}{C}\log{\frac{E_{ref}(f_i)}{E_q(f_i)}} $</li>
<li>重复2到收敛</li>
</ol>
其中，$ C=\max_{x,y}\sum_{i=1}^n{f_i(x,y)} $。
</p>


<p>根据上面算法，在最大熵模型的实现过程中，我们需要计算的值包括经验期望$E_{ref}(f)$和各轮迭代过后的模型期望$E_q(f)$。</p>


<p>经验期望$ E_{ref}(f_i)= \sum_{x,y}{\tilde{p}(x,y)f_i(x,y)} $，求$ E_{ref}(f_i)$只需要统计训练数据中符合$f_i$的(x,y)二元组的个数，然后除以训练实例的个数N。</p>


<p>模型期望需要首先求p(y|x)。这个条件概率可以通过简单地将所有(x,y)符合的$f_i$和对应的参数$\lambda_i$乘起来后相加。归一化因子是各个Outcome y的p(y|x)的和。在求得p(y|x)后，要求$E_q(f_i)$，只需要枚举所有符合$f_i$的(x,y)对应的p(y|x)，乘以Context x出现的次数再除以N就可以。</p>


<p>模型期望有了，经验期望有了，把他们一股脑儿放到算法里面去迭代就好了。</p>


<p>当然，到这里我们完全可以写出一个最大熵分类器。不过，需要注意的一点，在上文也提到最大化$\Psi(\lambda)$实际是在做最大似然估计。谈到最大似然估计，就不可避免想到了过拟合问题。如果训练数据和测试数据的偏置比较大。我们训练的模型很可能无法再测试数据上取得比较好的效果。解决这一问题的一般套路是用给待估计的参数一个先验分布做MAP，这里也不例外。如果假设$\lambda$服从Gauss分布，优化的目标函数就变成了$L_{\tilde{p}}^{'}(\Lambda)=L_p(\Lambda)+\sum_i{\log{\frac{1}{\sqrt{2\pi\sigma_i^2}}}}-\frac{\lambda_i^2}{2\sigma_i^2}$</p>


<p>在使用高斯先验平滑模型后，GIS的更新变成解$ E_{ref}(f_i)=E_q(f_i)e^{C\delta_i}+\frac{\lambda_i+\delta_i}{\sigma_i^2} $。其中，$\lambda_i$是本轮迭代的参数，$\delta_i$是更新$\lambda_i$的增量。上面的方程是没有解析解的，不过可以用牛顿法解除数值解。</p>


<h3>补充</h3>


<p>本来是想看一看lbfgs的，不过那个最优化的库实在是太复杂了，所以基本用的时候就当黑盒了。而且，从maxent的代码来看，其用法和GIS类似，都需要做求$ E_{ref}(f_i)$和$E_q(f_i)$的工作。</p>


<p>在了解了最大熵模型的一些实现细节后，我们就可以动手去实现一个最大熵分类器了。我用python写了一个GIS+binary feature版的maxent，去掉读写模型文件等外围模块，大概300行多一点。总体来讲是非常容易的。同时推荐阅读一下张乐的maxent toolkit，个人感觉写得非常好。</p>


<p></p>


<hr />


<h3>参考</h3>


<p>
<ul>
<li><a href="http://www.isi.edu/natural-language/people/ravichan/papers/bergeretal96.pdf">A Maximum Entropy Approach to Natural Language Processing</a> 个人感觉应该是最大熵必看的一篇论文。</li>
<li><a href="http://users.cms.caltech.edu/~weixl/research/read/summary/MaxEnt2.ppt">最大熵模型与自然语言处理</a> 感觉这个slide应该是基于上一篇做的，配合着看应该效果很好。</li>
<li><a href="http://work-tmp.googlecode.com/svn/trunk/maxent/10.1.1.123.127.pdf">The Improved Iterative Scaling Algorithm: A Gentle Introduction</a> 讲IIS为什么work</li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.714&rep=rep1&type=pdf">Investigating GIS and Smoothing for Maximum Entropy Taggers</a> 如果要实现一个maxent，这篇也是非常非常推荐的，从最基本的GIS到加高斯先验，后面还有必要的证明。</li>
<li><a href="http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html">Maximum Entropy Modeling Toolkit for Python and C++</a> 最大熵工具包，源码写得非常好看，无论从算法角度还是从软件工程角度。</li>
<li><a href="https://github.com/nicyun/easyME">easyME</a> nicyun等师兄实现的maxent toolkit的化简版，简单易懂。</li>
</ul>

</p>

 ]]></description>
        <pubDate>Sun, 22 Jul 2012 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2012/07/22/easy-implementation-on-maxent.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2012/07/22/easy-implementation-on-maxent.html</guid>
    </item>
    
    <item>
        <title>浅谈在线机器学习算法</title>
        <description><![CDATA[ <h3>前言</h3>

<p>这篇博客的内容基本是我本科毕设论文的第二章。
其中包括从毕设开始到现在，关于在线机器学习算法的一些粗浅的理解、算法的一些性质的证明以及算法如何从分类问题迁移到结构化预测问题，有些内容我也比较模糊，还有些内容太过繁琐，读者尽可能选择自己愿意接受的内容看，其他略过就好。</p>

<p><a id="more"></a><a id="more-600"></a></p>

<h3>机器学习的回顾</h3>

<p>机器学习是人工智能的一个分支。抽象讲，机器学习理论主要是设计和分析一些让计算机可以自动<strong>“学习”</strong>的算法。
机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。</p>

<p>通常来讲，机器学习分为<strong>学习</strong>以及<strong>推理</strong>两个阶段。在学习阶段，机器学习算法从数据中自动分析获取规律；在推理阶段，算法利用学习阶段学习到的规律对未知数据进行预测。</p>

<h3>序列标注问题</h3>

<p>在现实世界中，我们处理的某些机器学习任务，其面对的数据往往是序列性的。
在一个已知的类别体系下，算法需要对数据序列中的每个元素标注类别。
例如，中文分词任务需要给字序列中的每个字标“词首”、“词中”、“词尾”、“单字成词”四类中的某一类，词性标注任务需要将词序列中每个词标注一个已知词性集合下的词性。</p>

<p>结合之前关于机器学习的定义，可以将序列标注问题按如下方式定义，根据已知的序列性数据，学习一个假设h，并在这个假设h给定的条件下，预测某些未知序列性数据的序列标注。</p>

<p>形式化地，在给定一个序列性训练数据的集合 $(w_{[1:n]}^i, t_{[1:n]}^i)$的条件下，算法在学习阶段，从数据中学习一个假设h；在推理阶段，对于一个未知标注的序列$ w_{[1:n]} $，计算$ z_{[1:n]}=h(w_{[1:n]}) $。下面的讨论都会沿用这里对于序列和标注的形式化定义。</p>

<h3>在线机器学习</h3>

<p>(并不是指在网上授课机器学习课程)</p>

<p>在机器学习领域，在线机器学习(Online learning)指每次通过一个训练实例学习模型的学习方法。
Online learning的目的是正确预测训练实例的标注。其最重要的一个特点是当一次预测完成时，其正确结果便被获得，这一结果可直接用来修正模型。
通常来讲，一种Online learning算法对于一个序列进行一系列处理可以分为三步：第一步，算法获得一个训练实例；第二步，算法预测训练实例的类别；第三步，算法获得正确类别，并根据预测类别与正确类别更新模型假设。</p>

<p>下面介绍两种典型在线机器学习算法Perceptron、MIRA，他们都属于线性分类算法族。
介绍这两种算法在分类问题中如何从训练实例中学习模型参数，两种算法的收敛性。
同时介绍如何将这两种算法应用于解决序列标注问题。</p>

<h4>线性分类族</h4>

<p>属于线性分类族的几种机器学习算法具有相同的模型形式。在学习阶段，算法对于每个类别，通过训练数据估计一个参数向量w。在推理阶段，算法在给定一组参数向量w和数据x的条件下，以w和x的乘积作为数据与该类的相似度度量。</p>

<h4>Perceptron</h4>

<p>Perceptron一种有监督线性分类算法。算法将输入的实例分为正例、负例两类。在学习结果，算法从训练数据中实例估计w。推理阶段，算法基于特征向量x与参数向量w乘积的符号对于输入数据的类别进行预测。</p>

<h4>算法流程与收敛性</h4>

<p><strong>推理阶段</strong>，算法接受一个输入实例x，并根据权向量w确定其类别。设输入x是一个D维实向量，w是模型的权重向量，也是D维实向量。二元感知器按照输出函数$ w<sup>Tx</sup> $将输入x分为两类。将$ w<sup>T</sup> x>0 $的实例x分为正例；反之，分为负例。</p>

<p><strong>学习阶段</strong>，根据给定训练数据，感知器算法所学习的是模型的权重向量w，其学习算法下面所示。</p>

<table><tr><td style="border: 1px solid #000; background:#ddd">初始化权向量w为0，不失一般性，可以假设所有训练实例是单位向量。并置迭代次数t为1。利用感知器模型，对x的类别进行预测。如果$ w^tx>0 $，x是正例；否则，是负例。在判断正负例出错时，

<ul>
<li>将正例判成负例时，$ w_{(t+1)}\leftarrow w_{(t)}+x $</li>
<li>将负例判成正例时，$ w_{(t+1)}\leftarrow w_{(t)}-x $</li>
</ul>
</td></tr></table>




<p>训练算法迭代T轮，每轮迭代中枚举所有训练实例，按照推理阶段使用的方法预测训练实例类别。如果预测出错，则更新权重。直观上讲，算法给正确的分类的权向量增加，给错误分类的权向量减少。</p>


<p>可以证明上面的算法在训练数据线性可分以及线性不可分的情况下都是收敛的。在线性可分情况下，具体证明思路设一个理想的分类界面$ w^{*} $，再定义一个margin $ \gamma=\min{\frac{|w^*x|}{||x||}} $。然后证明随着迭代次数的增加，出错次数的下届增长得不是太慢，上届不是增长得不是太快，最后得到出错次数的一个界，也就证明了算法的收敛性。具体可以看<a href="http://www.cs.cmu.edu/~avrim/ML09/lect0126.pdf">这里</a>。</p>


<p>对于线性不可分的情况，证明方法是把不可分的数据“拉”到符合$ w^*$和$ \gamma$的位置。由于这个“拉”的代价是一个有界的值$ TD_{\gamma}$，在推导收敛性时，考虑这个值，其余的模仿线性可分的情况就好了。</p>


<h4>MIRA</h4>


<p>如前文所述，线性分类算法可以将实例分为二类。但是，实际问题面对的类别个数往往多于二类，需要将模型从二类问题推广到多类问题。</p>


<p>一种可行的将二类推广到多类的方法是"one-against-rest strategy"。这一策略将k类分类问题转化为k个二类分类问题。第r个二类分类器完成将训练实例分为是r类和不是r类两类。多于第r个类别的线性分类器，以其权向量$ w_r$与训练实例x的乘积作一种相似度度量。如果训练实例x的范数为1，那么，这一乘积可以从几何意义上解释为训练实例到类r的分类面的距离。之前江枫师兄说：“一般认为离分类面r越远的数据点，其属于r类的可能性就越大。”实际使用online算法处理多类问题时，也把和数据点x乘积最大的$ w_r$作为x的类别。</p>


<p>MIRA算法也是一种有监督在线机器学习算法，与perceptron相似，MIRA算法也是一种线性分类算法。在使用MIRA解决分类问题时，算法从训练实例中学习一个k行的参数矩阵M，其中第r行Mr表示第r类的参数向量。</p>


<h4>算法流程与收敛性</h4>


<p>在推理阶段，算法计算训练实例x和各类参数向量的乘积，作为该训练实例与该类的相似度。并将相似度最高的一类作为对训练实例类别的预测。</p>


<p>在学习阶段，算法流程如下
<table><tr><td style="border: 1px solid #000; background:#ddd">
<ol>
<li>对于k类分类问题，设由各类权向量组成的矩阵M。其中M有k行，第r行向量$ M_r$对应第r类的分类权向量。</li>
<li>从1到T循环每个训练实例$ x^t $
<ul>
<li>对于每个训练实例$ x^t$，依照$ y=\arg_r{\max{M_rx}}$预测$ x^t$的类别。</li>
<li>依照下面的优化目标和约束条件：
obj. $ \min_{\tau}{\frac{1}{2}\sum_r||M_r+\tau_{r}x^{(t)}||^2} $<br />
st.(1)$ \tau_r\le\sigma_{x,y^t} $<br />
(2)$ \sum{\tau_r}=0$ </li></ul></li>
<li>依照$ M_r^{(t+1)}=M_r^{(t)}+\tau_r x^t$更新M</li></ol>
</td></tr></table></p>


<p>MIRA的收敛性证明要比perceptron复杂，但是思路也是证明“出错次数的下届增长得不是太慢，上届不是增长得不是太快”。如果感兴趣，可以看Crammer的<a href="http://jmlr.csail.mit.edu/papers/volume3/crammer03a/crammer03a.pdf"><em>Ultraconservation Online Algorithms for Multiclass Problems</em></a></p>


<h4>从分类问题到序列标注问题</h4>


<p>如之前对于序列标注问题的描述，假如序列长度为n，有k个类别，那么这个序列就存在$ n^k$种标注。所以，在推理阶段将$ y=\arg_r{max{M_r x^t}}$换成$ z_{[1:n_i]}=\arg{\max_{u[1:n_i]\in\mathcal{T}^{n_i}}\sum_s{\alpha_s\Phi_s(w_{[1:n_i]}^i,u_{[1:n_i]})}}$，也就是将用分类面判断类别变成求序列的最优标注。这样序列标注问题就转化为分类问题了。</p>


<p>当然，对于用perceptron处理序列标注问题来讲，直接用viterbi求一个最优标注并用这个最优标注和标准结果更新参数就好了。但是，我们注意到MIRA在用一个训练实例更新参数时，实际对于各个类别都进行了更新。而序列标注问题的类别数是指数级别，对每个类别都更新显然是不现实的。McDonald在<a href="http://acl.ldc.upenn.edu/eacl2006/main/papers/04_2_mcdonaldpereira_26.pdf"><em>Online Large-Margin Training of Dependency Parsers</em></a>这篇论文中提出这一问题的一个解决方案，即假设影响参数更新的序列只有少数解码过程中分数比较高的序列。所以，用k-best viterbi算法求k个序列标注结果。然后用这k个结果按照mira算法中的二次规划求第r类的更新权重$ \tau_r$并更新参数。这里，McDonald也提到，实验表明，k如果过大，算法就很快过拟合训练数据了。</p>


<hr />


<p>这篇文章参考了以下论文和资源：
<ul>
<li>Discriminative Training Methods for Hidden Markov Models</li>
<li>Online Large-Margin Training of Dependency Parsers</li>
<li>Ultraconservative Online Algorithms for Multiclass Problems</li>
</ul>
</p>

 ]]></description>
        <pubDate>Sat, 14 Jul 2012 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2012/07/14/a-brief-talk-about-online-learning.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2012/07/14/a-brief-talk-about-online-learning.html</guid>
    </item>
    
    <item>
        <title>Sunner的毕业寄语</title>
        <description><![CDATA[ <p>几天前，为毕业晚会剪了学院老师的寄语视频。其间为了整体效果，把很多老师的寄语剪得支离破碎，导致好几段逻辑比较严密的访谈看起来都比较突兀。这里在征得了sunner的同意后，把他那段寄语单独拿了出来，算是我把事情交代清楚了。</p>


<p>PS：那处NG我就不说啥了。</p>


<p><a id="more"></a><a id="more-603"></a></p>

<p><strong>视频原片</strong><br /><div align="center"><embed src="http://player.youku.com/player.php/sid/XNDIwNDE1ODEy/v.swf" allowFullScreen="true" quality="high" width="480" height="400" allowScriptAccess="always" type="application/x-shockwave-flash"></embed></div></p>


<p><strong>访谈录</strong>
<div style="background:#000; color:#fff; padding:10px">
&nbsp;&nbsp;&nbsp;&nbsp;Hi，08级的同学们。你们好，恭喜你们终于悲催地毕业了。为什么悲催呢。你们上大学开始就注定了你们是悲催的一届。因为你们是在2012年毕业。世界末日啊。刚毕业就碰上世界末日，这是很悲催的事情。
&nbsp;&nbsp;&nbsp;&nbsp;你知道，毕业，最主要的意味着，在我的感觉来说，它是获得了一个真正的自由。自由啦，却世界末日了。
&nbsp;&nbsp;&nbsp;&nbsp;其实很多人说上了大学就开始可以享受自由了。但是在工大这样的环境里面。这个什么规格严格啊，功夫到家啊这一切把你严格地限死了。所以在大学里面我们通常享受不到太多的自由。即便有一些自由的地方，因为你们没有经历过自由，所以不懂得如何利用它。所以，大学四年里面，回想一下，自由自在做的事情是什么呢。大概也就是玩玩dota、泡泡妞、什么什么这个样子的了。其他就很少了。但是从现在开始，你们真正的获得自由了。这是完全完全不一样的一个体验。因为现在开始，你可以按照自己的意愿决定自己的人生。决定自己将来每一步，做得每一件事情。你不用再看别人的脸色，甚至来说。你们的经济也可以开始趋向于独立。经济独立了，那么，腰板就硬起来了。
&nbsp;&nbsp;&nbsp;&nbsp;不过坦率的说，其实在我看来我觉得现在这个社会上大多数人还是不懂得享受这个自由。他们仍然是喜欢按照循规蹈矩的，按照别人划定的路线去走，去做。所以呢，要是我建议你们什么呢。我倒是建议你们能够按照自己的想法，自己的理想发自自己内心的想干什么就干什么不要去太过多于听从前辈们的建议。前辈们的建议到底是什么样的东西呢，我经常做这样的一个比喻：就是说，如果他们为我们划定的路线是好的，或者他们走过的路线是好的那么现在的世界一定是非常美妙的。但是现在的世界明显不是美妙的。所以，他们一定是有问题的。如果我们按照他们所说的去做的话，其结果就是把这个世界变得更加不美妙。因此，我希望你们成为一个完全不同的一代的人。那就是说，2012作为一个分水岭。把他，让他，2012肯定不是世界末日。但是因为你们的存在，他能成为旧世界的末日。你们能够创建一个新的世界，完全发自自己内心的去做自己想做的事情。而且事情一定要对得起自己的良心。只要对得起自己的良心，那么现在就已经是一个非常非常伟大的人了。</div></p>

 ]]></description>
        <pubDate>Wed, 27 Jun 2012 00:00:00 +0800</pubDate>
        <link>http://yjliu.net/blog/2012/06/27/wishes-from-sunner.html</link>
        <guid isPermaLink="true">http://yjliu.net/blog/2012/06/27/wishes-from-sunner.html</guid>
    </item>
    
</channel>
</rss>
